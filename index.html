<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Multimodal large language models converge on the human-like geometry of abstract emotion">
  <meta name="keywords" content="LLM, Affective Representation, Human-like, brain-aligned">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AI Emotion</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/BCI.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Multimodal large language models converge on the human-like geometry of abstract emotion</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://changdedu.github.io/">Changde Du</a><sup>1,3,†</sup>,</span>
            <span class="author-block">
              <a href="https://reedonepeck.github.io/Luyizhuo.github.io/">Yizhuo Lu</a><sup>1,2,†</sup>,</span>
            <span class="author-block">
              Zhongyu Huang<sup>1,3,†</sup>,
            </span>
            <span class="author-block">
              Yi Sun<sup>1,3</sup>,
            </span>
	    <span class="author-block">
              Zisen Zhou<sup>4</sup>,
            </span>
	    <span class="author-block">
              <a href="https://imibr.bnu.edu.cn/English/Faculty/PIen/faa01d662a7f438f8614f3e14e6d27e9.htm">Shaozheng Qin</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://people.ucas.ac.cn/~hehuiguang">Huiguang He</a><sup>1,2,3,*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <!-- 单位列表（分行显示） -->
            <div class="author-block"><sup>1</sup>State Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China.</div>
            <div class="author-block"><sup>2</sup>School of Future Technology, University of Chinese Academy of Sciences, Beijing, 100049, China.</div>
            <div class="author-block"><sup>3</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China</div>
	    <div class="author-block"><sup>4</sup>State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, China</div>
            
            <!-- 通讯作者和同等贡献说明 -->
            <div class="author-block" style="margin-top: 0.5rem;">
              <sup>†</sup>These authors contributed equally<br>
              <sup>*</sup>corresponding author: Huiguang He (huiguang.he@ia.ac.cn)
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>



	
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Understanding whether artificial intelligence (AI) systems represent abstract concepts in a human-like manner is pivotal for developing trustworthy AI. 
			  While recent work has aligned model representations with human concrete visual object concepts, it remains unclear whether such alignment extends to the subjective and context-dependent domain of emotion. 
			  Here, we investigate the emergent affective geometry in large language models (LLMs) and multimodal LLMs (MLLMs) through a large-scale, unsupervised ``machine-behavioral'' paradigm. By deriving 30-dimensional embeddings 
			  from over 12 million triplet odd-one-out judgments on 2,180 emotionally evocative videos, we reveal a sophisticated ``hybrid'' geometry. This structure synthesizes categorical clusters with continuous dimensions, 
			  showing strong selective correlations with human ratings across 34 emotion categories and 14 affective dimensions, effectively reconciling the long-standing category-versus-dimension debate in affective science. 
			  To demonstrate the operational utility of these representations, we introduce a generative editing framework, showing that manipulating specific affective components actively steers generated video content in a predictable,
			  human-interpretable manner. Crucially, at the neural level, the MLLM-derived affective space predicts human fMRI activity in high-level social-emotional regions (e.g., temporoparietal junction) with accuracy matching 
			  or exceeding traditional human self-report ratings. These findings demonstrate that MLLMs converge on a biologically plausible, brain-aligned representational scheme for abstract emotion, distinguishing them from models 
			  of pure visual perception and establishing a framework for artificial social intelligence.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>




	

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">

      <!-- 居中标题（使用Bulma内置类） -->
      <div class="has-text-centered mb-6">
        <h2 class="title is-3">Visualization of MLLM's 30-dimensional affective embeddings, with the top 9 video stimuli exhibiting the highest activation in each dimension.</h2>
      </div>
      
      
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-dim_1">
          <video poster="" id="dim_1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_2">
          <video poster="" id="dim_2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_3">
          <video poster="" id="dim_3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_4">
          <video poster="" id="dim_4" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_5">
          <video poster="" id="dim_5" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_6">
          <video poster="" id="dim_6" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_7">
          <video poster="" id="dim_7" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_7.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_8">
          <video poster="" id="dim_8" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_8.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_9">
          <video poster="" id="dim_9" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_9.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_10">
          <video poster="" id="dim_10" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/blurred_dim10_video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_11">
          <video poster="" id="dim_11" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_11.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_12">
          <video poster="" id="dim_12" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/blurred_dim12_video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_13">
          <video poster="" id="dim_13" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_13.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_14">
          <video poster="" id="dim_14" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_14.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_15">
          <video poster="" id="dim_15" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_15.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_16">
          <video poster="" id="dim_16" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_16.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_17">
          <video poster="" id="dim_17" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_17.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_18">
          <video poster="" id="dim_18" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_18.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_19">
          <video poster="" id="dim_19" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_19.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_20">
          <video poster="" id="dim_20" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_20.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_21">
          <video poster="" id="dim_21" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_21.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_22">
          <video poster="" id="dim_22" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_22.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_23">
          <video poster="" id="dim_23" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_23.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_24">
          <video poster="" id="dim_24" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_24.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_25">
          <video poster="" id="dim_25" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_25.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_26">
          <video poster="" id="dim_26" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_26.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_27">
          <video poster="" id="dim_27" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_27.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_28">
          <video poster="" id="dim_28" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_28.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_29">
          <video poster="" id="dim_29" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_29.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-dim_30">
          <video poster="" id="dim_30" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/MLLM/dim_30.mp4"
                    type="video/mp4">
          </video>
        </div>
          
      </div>
    </div>
  </div>
</section>



<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">

      <!-- 居中标题（使用Bulma内置类） -->
      <div class="has-text-centered mb-6">
        <h2 class="title is-3">Visualization of LLM's 30-dimensional affective embeddings.</h2>
      </div>
      
      
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-llm-dim_1">
          <video poster="" id="llm-dim_1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_2">
          <video poster="" id="llm-dim_2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_3">
          <video poster="" id="llm-dim_3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_3.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_4">
          <video poster="" id="llm-dim_4" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_5">
          <video poster="" id="llm-dim_5" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_6">
          <video poster="" id="llm-dim_6" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_7">
          <video poster="" id="llm-dim_7" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_7.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_8">
          <video poster="" id="llm-dim_8" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_8.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_9">
          <video poster="" id="llm-dim_9" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_9.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_10">
          <video poster="" id="llm-dim_10" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_10.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_11">
          <video poster="" id="llm-dim_11" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_11.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_12">
          <video poster="" id="llm-dim_12" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_13">
          <video poster="" id="llm-dim_13" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_13.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_14">
          <video poster="" id="llm-dim_14" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_14.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_15">
          <video poster="" id="llm-dim_15" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_15.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_16">
          <video poster="" id="llm-dim_16" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_16.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_17">
          <video poster="" id="llm-dim_17" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_17.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_18">
          <video poster="" id="llm-dim_18" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_18.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_19">
          <video poster="" id="llm-dim_19" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_19.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_20">
          <video poster="" id="llm-dim_20" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_20.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_21">
          <video poster="" id="llm-dim_21" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_21.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_22">
          <video poster="" id="llm-dim_22" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_22.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_23">
          <video poster="" id="llm-dim_23" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/blurred_dim23_video.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_24">
          <video poster="" id="llm-dim_24" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_24.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_25">
          <video poster="" id="llm-dim_25" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_25.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_26">
          <video poster="" id="llm-dim_26" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_26.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_27">
          <video poster="" id="llm-dim_27" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_27.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_28">
          <video poster="" id="llm-dim_28" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_28.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_29">
          <video poster="" id="llm-dim_29" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_29.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-llm-dim_30">
          <video poster="" id="llm-dim_30" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/LLM/dim_30.mp4"
                    type="video/mp4">
          </video>
        </div>
          
      </div>
    </div>
  </div>
</section>









  

<!-- 图1 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Overview of our work.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/fig1_new.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
        <h3>Overview of the experimental and analytical pipeline.</h3>
        <p><b>a</b>, The study utilized a database of 2,180 emotionally evocative videos with rich, pre-existing annotations, including human ratings on discrete emotion categories and continuous affective dimensions, detailed textual descriptions, and corresponding fMRI data from human viewers.
        <b>b-d</b>, MLLM (<b>b</b>) and LLM (<b>c</b>) use a triplet odd-one-out behavioral paradigm to collect millions of triplet judgments, and the latent embeddings of videos were learned from these judgments by using SPoSE (<b>d</b>).
			<b>e</b>, Example prompts and responses for the LLM and MLLM. <b>f</b>, Testing the behavioral consistency between human and various AI models (across architectures, scales, and modalities) on a newly collected dataset of 30,000 triplet judgments from human participants (n=100). <b>g</b>, Comparing the model-derived representations against traditional human rating models in predicting brain activity.</p>
	  </div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>





<!-- 图2 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Embeddings derived from model behavior are low-dimensional, stable, and predictive.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/result1.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Model-derived affective embeddings are low-dimensional, robust, and predictive.</h3>
  <p><b>a</b>, Effect of dimensionality on the ability of embeddings to predict held-out similarity judgments, showing performance saturation at approximately 30 components.
  <b>b-c</b>, Reproducibility of the 30 learned components across ten independent model runs. Each point is the maximum correlation of a component from one run with all components from the other runs. Shaded areas represent 95% confidence intervals (CIs).
  <b>d-e</b>, Comparison of RSMs for 66 validation stimuli. Left: RSMs predicted by the learned embeddings. Middle: RSMs measured from empirical behavioral choices (unavailable in the SPoSE training). Right: Pearson's correlation between predicted and measured RSMs, indicating high global correspondence.
  <b>f</b>, Prediction accuracy of the 30-dimensional embeddings on held-out triplets. Noise ceilings indicate the upper bound of explainable variance estimated from trial-to-trial reliability (across 10,000 trials). Error bars represent 95% CIs estimated from 1,000 bootstrap iterations.
  <b>g-h</b>, Dimensionality reduction analysis showing the minimum number of principal components required to retain 95%–99% of the predictive accuracy on the behavioral task (gray shaded area). The red dashed line indicates chance-level accuracy (33.3%).</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>


	

	
<!-- 图3 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Human-like affective structure emerges in model-derived embeddings.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/result2.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
        <h3>Human-like emotion categories and affective dimensions emerge in the derived embeddings.</h3>
        <p><b>a</b>, Global structure of the 30-dimensional affective space visualized using t-SNE, with points colored by human emotion categories.
        <b>b</b>, Top-3 nearest-centroid classification accuracy, quantifying the categorical structure.
		<b>c-d</b>, Correlations (Pearson's r) between model-derived components and human-rated emotion categories or affective dimensions.
			<b>e</b>, Proportion of components best described as categorical, dimensional, or hybrid. <b>f</b>, Percentage of components with significant r>thresholds (P<0.05, FDR corrected).</p>
	  </div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>



<!-- 图4 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Human-like affective structure emerges in model-derived embeddings.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/result3.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Examples of affective components.</h3>
  <p>Top-weighted video frames and word clouds (label size proportional to correlation with human ratings) for representative components.
  <b>a</b>, Components primarily encoding discrete emotion categories.
  <b>b</b>, Components primarily encoding affective dimensions (LLM specific).
  <b>c</b>, Components exhibiting a hybrid coding scheme, bridging categories and dimensions. Left panels: LLM; Right panels: MLLM.</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>




<!-- 图5 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Revealing the link between affective components and visual content.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/figure5.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Visual attribution and generative editing validate the role of affective components.</h3>
  <p><b>a,</b> Affective decomposition of example videos: each colored petal represents a specific affective component, with its length proportional to the component's weight. <b>b,</b> Grad-CAM heatmaps localize visual regions driving specific component activations (red indicates high contribution). <b>c,</b> Targeted reduction of an affective component by decreasing its activation (component marked in red box, activation normalized to [0,1]). <b>d,</b> Generative elicitation of emotional content by increasing specific component activations.</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>













<!-- 图6 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Affective structure and behavioral alignment across models and humans.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/result4.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Convergent and divergent high-level affective structures.</h3>
  <p><b>a-d</b>, Affective graphs (left) and community structure (right) for each of the four spaces. In the graphs, nodes are affective components, and edge width is proportional to the Pearson correlation between them (r > 0.2). In the community plots, components are grouped into clusters using the Louvain algorithm, with node size reflecting PageRank centrality. Isolated nodes are excluded.
  <b>e</b>, The overlap of affective clusters across all four spaces, highlighting both shared and unique high-level structures.
  <b>f</b>, Human–model behavioral consistency across architectures. Scores are noise-normalized relative to the human noise ceiling. Error bars represent 95% CIs (n=1,000 bootstrap iterations).</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>









<!-- 图7 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Neural alignment of model-derived affective representations.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/result5.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Neural alignment of model-derived and human-rated affective representations.</h3>
  <p><b>a, b</b>, Results of searchlight RSA between different affective representations and human brain activity, averaged in subcortical (<b>a</b>) and cortical (<b>b</b>) ROIs (averaged across subjects (n=5)). Dots represent individual subjects; error bars reflect standard deviation (s.d.) across subjects; asterisks indicate significant differences between MLLM and competing models (*, P < 0.05; **, P < 0.01; ***, P < 0.001; n.s., not significant); all statistics are paired t-tests (two-tailed), with FDR correction for multiple comparisons across ROIs.
  <b>c</b>, Whole-cortex maps of searchlight RSA for a representative subject. All coloured voxels are predicted significantly (P < 0.05, FDR corrected, two-tailed t-tests).
  <b>d</b>, Voxel-wise comparison of model performance using searchlight RSA.</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>





<!-- 图supp1 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Neural alignment of model-derived affective representations.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/supp1.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Cortical topography of specific MLLM affective components.</h3>
  <p>This figure shows the brain activation patterns triggered by three distinct affective components from the MLLM, generated from the weights of the voxel-wise encoding models. Each row displays the results for a single subject (S1–S5), and each column corresponds to a specific component (e.g., <i>nostalgia</i>, <i>sexual desire</i>, <i>anger</i>). Red indicates positive weights, reflecting brain regions where activity is positively associated with the affective component; blue indicates negative weights, reflecting regions with a negative association. For visualization purposes, the original weights have been normalized to the range of -1 to 1, and voxels with absolute values less than 0.01 have been masked out. The consistency in the spatial patterns across all five subjects suggests that these learned affective components capture neurally meaningful and stable components of emotion processing.</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>
	

	

<!-- 图supp2 -->
<section class="image-showcase">
  <div class="image-container">
    <div class="image-content">
      <!-- 1. 作为section标题显示在图像上方 -->
      <h2 class="section-title">
        <span class="highlight">Neural alignment of model-derived affective representations.</span> 
      </h2>
      
      <!-- 2. 大尺寸图片容器 -->
      <div class="image-wrapper">
        <img src="./static/images/supp2.png">
      </div>
      
      <!-- 3. 等宽描述区域 -->
      <div class="image-caption">
  <h3>Searchlight RSA comparisons against visual, semantic, and motion control models.</h3>
  <p><b>a, b,</b> RSA scores (Spearman's rank correlation) averaged for subcortical (<b>a</b>) and cortical (<b>b</b>) ROIs across subjects (n=5). The MLLM-derived affective representation is compared against Visual Object Features (VGG19), Semantic Features (73 concepts), and Motion Energy Features. Error bars reflect standard deviation (s.d.). Asterisks indicate significant differences between MLLM and the comparison models (*, P < 0.05; **, P < 0.01; ***, P < 0.001; n.s., not significant; paired t-tests (two-tailed), FDR corrected). <b>c,</b> Voxel-wise difference maps for a representative subject (S1). Regions where MLLM SPoSE yields higher RSA scores than the visual object and semantic features are shown in yellow-red. The comparison with motion energy features is omitted from the maps as MLLM outperforms them across nearly all voxels. These maps highlight the MLLM's specific advantage in higher-order cortical networks over pure visual features, and its broad advantage over semantic features, particularly in subcortical regions.</p>
</div>
    </div>
  </div>
</section>
<style>
  /* 图片展示区域专用样式 */
  .image-showcase {
    margin: 60px 0;
  }
  
  .image-showcase .image-container {
    max-width: 1000px;
    margin: 0 auto;
  }
  
  .image-showcase .image-content {
    padding: 30px;
    background: white;
    border-radius: 12px;
    box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
  }
  
  /* 作为section标题的样式 - 在图像上方 */
  .image-showcase .section-title {
    font-size: 2.2rem;
    color: #2c3e50;
    text-align: center;
    margin: 0 0 40px 0; /* 下方留出足够间距 */
    padding: 0 0 20px 0; /* 下方内边距 */
    border-bottom: 3px solid #3498db;
    position: relative;
    display: block;
    width: 100%;
  }
  
  .image-showcase .highlight {
    font-weight: 800;
    color: #e74c3c;
    text-transform: uppercase;
    letter-spacing: 1px;
  }
  
  .image-showcase .image-wrapper {
    width: 100%;
    margin: 0 auto 30px;
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
  }
  
  .image-showcase .image-wrapper img {
    width: 100%;
    height: auto;
    display: block;
  }
  
  .image-showcase .image-caption {
    width: 100%;
    padding: 25px;
    background: #f8f9fa;
    border-radius: 10px;
    border-left: 5px solid #3498db;
  }
  
  .image-showcase .image-caption h3 {
    color: #2c3e50;
    margin-bottom: 15px;
    font-size: 1.4rem;
  }
  
  .image-showcase .image-caption p {
    color: #555;
    font-size: 1.1rem;
    line-height: 1.8;
  }
  
  /* 响应式调整 */
  @media (max-width: 768px) {
    .image-showcase .image-content {
      padding: 20px;
    }
    
    .image-showcase .section-title {
      font-size: 1.8rem;
      margin-bottom: 30px;
    }
    
    .image-showcase .image-caption {
      padding: 15px;
    }
  }
</style>


	











<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
		  The framework and source code were adapted from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies website</a>. 
		  Special thanks to the Nerfies team for their awesome open-source project.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
